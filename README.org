** R abstract

Title: Optimizing ROC curves using torch in R

Receiver Operating Characteristic (ROC) curves are useful for
evaluating binary classification models, especially when data are
unbalanced (97% negative, 3% positive, etc). We propose a new
surrogate loss function called the AUM, which can be used to optimize
ROC curves during gradient descent learning. Whereas previous loss
functions are based on summing over all labeled examples or pairs, the
AUM requires a sort and a sum over the sequence of points on the ROC
curve. We show how the AUM loss can be easily implemented in torch
code (using R or python), so the ROC curve optimization objective can
be used during neural network training (in addition to its typical use
for evaluation). In our empirical study of unbalanced binary
classification problems, we show that our new AUM minimization
learning algorithm results in improved AUC and speed relative to
previous baselines.

** Title, abstract, slides

Title: Two new algorithms for scientific applications of machine learning

Speaker: Toby Dylan HOCKING, https://tdhock.github.io/

Abstract: In the last few years, I have maintained active
collaborations with scientists who are not machine learning experts,
but who want to use machine learning algorithms for their data
analyses. In many scientific applications of machine learning, two
questions come up again and again. 
- Question 1. we have some data from one region (or time period), so
  if we use these data to train, will it work on a new region? (or
  time period) 
- Question 2. how do we deal with class imbalance?  
- Example A: forestry. When predicting forest properties based on
  objects in satellite images, if we train on one region (say
  Arizona), will it work in another? (California or Quebec) How to
  deal with the fact that some objects of interest (trees, burn) are
  only a small minority of data?
- Example B: medicine. When predicting autism diagnosis from other
  survey responses, if we train on one year of survey data (say 2019),
  will it work in another year? (say 2020) And can we combine the two
  years of data to get a better model? How to deal with the fact that
  autism represents only 3% of the total surveys? (97% of survey
  respondants did not have autism)
- For Question 1, we propose a new algorithm called SOAK
  (Same/Other/All K-fold Cross-Validation), which can be used to quantify the extent to
  which it is possible to predict on a given data subset, after training
  on Same/Other/All data subsets. https://arxiv.org/abs/2410.08643 
- For Question 2, we propose a new differentiable loss function which
  can be used to optimize the ROC curve,
  https://jmlr.org/papers/v24/21-0751.html 
- I am a new professor at Universit√© de Sherbrooke since June 2024,
  and I am open to collaborative research projects / co-supervising
  students.

Slides PDF [[file:HOCKING-two-new-algos-sci-ml-slides.pdf]]

Source files
- [[file:HOCKING-two-new-algos-sci-ml-slides.tex]]
- https://github.com/tdhock/max-generalized-auc
- https://github.com/tdhock/cv-same-other-paper with [[https://github.com/tdhock/cv-same-other-paper?tab=readme-ov-file#9-apr-2024][older slides showing different details]].

Software
- [[https://cloud.r-project.org/web/packages/mlr3resampling/][mlr3resampling]] R package implements SOAK algorithm, [[https://cloud.r-project.org/web/packages/mlr3resampling/vignettes/Newer_resamplers.html][tutorial]].
- [[https://tdhock.github.io/blog/2024/torch-roc-aum/][AUC and AUM in torch]] blog explaining how to implement AUM.
- [[https://cloud.r-project.org/web/packages/aum/][aum]] R package implements directional derivatives and efficient line search.
